# 自动提示词生成与执行系统

## 项目简介

本项目实现了一个智能的自动提示词生成与执行系统，能够根据用户需求智能选择最适合的AI模型，让AI自动生成优化的提示词，并将这些提示词传递给AI系统执行，最终高质量地完成用户需求并生成任务报告。

系统工作流程：
1. 用户输入自然语言需求
2. **让最聪明的AI模型分析需求并从可用模型中选择最适合的模型**
3. 让AI根据需求自动生成高质量的提示词
4. 系统将生成的提示词传递给AI执行具体任务
5. 系统根据任务类型自动处理执行结果（如保存代码文件、文档等）
6. 系统自动生成任务完成报告，并保存为Markdown文件

系统包含以下核心组件：
1. 需求解析器 - 智能分析用户输入的自然语言需求
2. 模型管理器 - 管理AI模型选择和token使用情况
3. 提示词生成器 - 让AI自动生成高质量的提示词
4. AI执行器 - 将提示词传递给AI系统执行
5. 结果处理器 - 根据任务类型自动处理AI执行结果

## 功能特点

- **AI驱动的智能模型选择**：让最聪明的AI模型分析需求并选择最适合的模型
- **实时从Qwen平台获取token使用情况**：确保模型选择基于准确的使用数据
- 让AI自动生成提示词，而非程序生成
- 根据任务类型智能处理AI执行结果
- **自动生成详细任务报告（无论成功或失败）**
- **保存AI生成的提示词为MD文件，供用户手动使用**
- **完全基于真实API调用，非演示或模拟**
- 支持多种大模型（包括阿里云百炼平台上的Qwen系列模型）
- 模块化设计，易于扩展和维护
- 集成真实的AI服务

## 安装依赖

```bash
pip install -r requirements.txt
```

## 配置

在使用真实AI服务之前，需要配置API密钥：

### 使用阿里云百炼平台（推荐）

系统默认配置了阿里云百炼平台的Qwen系列模型，您只需要在`.env`文件中填入您的API密钥即可：

```env
OPENAI_API_KEY=your_qwen_api_key_here
```

系统支持以下模型：
- qwen-turbo: 超快推理速度的推理模型
- qwen-plus: 推理效果与成本平衡的推理模型
- qwen-max: 推理效果最好的推理模型
- qwen3: 最新的Qwen3大语言模型
- qwen2.5: Qwen2.5大语言模型
- qwen2: Qwen2大语言模型
- qwen1.5: Qwen1.5大语言模型
- qwen-long: 支持长文本输入的推理模型
- qwen-vl-max: 效果最好的视觉语言模型
- qwen-vl-plus: 效果与成本平衡的视觉语言模型

### 使用其他AI服务

系统也支持其他兼容OpenAI API的服务，您可以修改`.env`文件中的配置：

```env
# OpenAI API配置示例
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
DEFAULT_MODEL=gpt-3.5-turbo
```

### 配置参数说明

- `OPENAI_API_KEY`: AI服务的API密钥
- `OPENAI_BASE_URL`: API的基础URL
- `DEFAULT_MODEL`: 使用的默认模型
- `MAX_TOKENS`: 最大生成令牌数
- `TEMPERATURE`: 生成文本的随机性（0-1之间，值越大越随机）

## 使用方法

### 命令行全自动执行模式

```bash
python auto_prompt_system.py
```

运行后，系统会提示您输入需求，输入需求后系统会全自动完成以下任务：
1. 让最聪明的AI模型分析需求并选择合适的模型
2. 让AI生成提示词
3. 执行AI任务
4. 根据任务类型自动处理结果（如保存代码文件、文档等）
5. **生成详细任务报告（无论成功或失败）**
6. **保存AI生成的提示词为MD文件**
7. 保存报告到文件
8. 输出最终结果

### 纯粹AI管道模式（完全由AI决策）

```bash
python pure_ai_pipeline.py
```

此模式下，系统完全由AI负责所有决策和执行工作，程序只充当管道和结果保存器：
1. 用户输入需求
2. AI完全自主分析、决策和执行
3. 程序只负责保存AI生成的结果
4. **生成详细任务报告（无论成功或失败）**
5. **保存AI生成的提示词为MD文件**

### 终极AI系统模式

```bash
python ultimate_ai_system.py
```

此模式下，系统实现完全的AI自主性：
1. 用户表达意愿
2. AI完全自主理解和执行
3. 程序仅作为执行环境和保存器
4. **生成详细任务报告（无论成功或失败）**
5. **保存AI生成的提示词为MD文件**

### 通用AI生成器模式

```bash
python universal_ai_generator.py
```

此模式是一个通用的内容生成器：
1. 用户输入任何请求
2. 系统自动分析并处理
3. 生成相应内容并保存
4. **生成详细任务报告（无论成功或失败）**
5. **保存AI生成的提示词为MD文件**

### 代码中使用

```python
from auto_prompt_system import AutoPromptSystem
from pure_ai_pipeline import PureAIPipeline
from ultimate_ai_system import UltimateAISystem
from universal_ai_generator import UniversalAIContentGenerator

# 使用标准系统
system = AutoPromptSystem()
result = system.auto_execute("请用Python写一个快速排序算法")

# 使用纯粹AI管道系统
pipeline = PureAIPipeline()
result = pipeline.fulfill_user_requirement("请用Python写一个快速排序算法")

# 使用终极AI系统
ultimate_system = UltimateAISystem()
result = ultimate_system.execute_user_will("请用Python写一个快速排序算法")

# 使用通用AI生成器
generator = UniversalAIContentGenerator()
result = generator.generate_content("生成一张可爱的小孩照片")
```

## 系统架构

```
+-------------------+
|   用户需求输入    |
+-------------------+
          |
          v
+-------------------+
|  需求解析与文件读取 |
+-------------------+
          |
          v
+-------------------+
| AI智能模型选择模块 |
+-------------------+
          |
          v
+-------------------+
| AI提示词生成模块  |
+-------------------+
          |
          v
+-------------------+
|   AI任务执行模块   |
+-------------------+
          |
          v
+-------------------+
|  结果评估与处理模块 |
+-------------------+
          |
          v
+-------------------+
|   文件保存模块    |
+-------------------+
```

## AI驱动的模型选择

系统采用先进的AI驱动模型选择机制：

1. **智能需求分析**：使用最聪明的可用AI模型分析用户需求
2. **模型推荐**：AI从可用模型列表中选择最适合执行该任务的模型
3. **使用率监控**：系统可以监控各模型token使用情况（基于环境变量配置的模型ID）
4. **自动切换**：可根据模型使用情况自动选择其他可用模型

## Token使用情况管理

系统具备token使用情况管理功能：

1. **数据获取**：可以从Qwen平台获取各模型的token使用情况
2. **准确监控**：监控输入、输出、传递、AI思考等每个环节的token消耗
3. **智能切换**：基于使用数据进行模型选择和切换
4. **数据持久化**：将token使用情况保存到本地文件以供后备使用
5. **真实数据**：所有功能基于真实API调用

## 自动结果处理

系统能够根据任务类型自动处理AI执行结果：

- **代码任务**：自动识别编程语言并保存为相应格式的代码文件
- **文档任务**：自动保存为Markdown或文本文件
- **图像任务**：自动识别并处理图像文件，支持读取PNG、JPG、GIF、BMP等格式的图像
- **其他任务**：直接返回文本结果

## 详细报告和提示词保存

所有系统都具备以下增强功能：

1. **详细任务报告**：
   - 无论任务成功或失败都生成详细报告
   - 报告包含任务信息、处理过程、结果详情等
   - 报告以Markdown格式保存，便于查看和分享

2. **提示词保存**：
   - 将AI生成的提示词保存为MD文件
   - 文件名与用户需求相关，便于识别
   - 用户可以手动使用这些提示词在其他AI服务中生成内容

## 纯粹AI管道模式

系统提供纯粹AI管道模式，在此模式下：

1. **完全AI决策**：AI完全自主分析、决策和执行用户需求
2. **程序仅管道**：程序只充当管道和结果保存器
3. **最小干预**：程序不对AI的决策和执行过程进行干预

## 扩展性

1. **改进需求解析**：修改[RequirementParser](file:///c%3A/myproject/AI/auto_prompt_system.py#L13-L193)类以支持更复杂的需求解析
2. **集成其他AI服务**：修改[AIExecutor](file:///c%3A/myproject/AI/auto_prompt_system.py#L257-L332)类以集成其他 AI 服务 API
3. **添加新的结果处理类型**：修改[_process_result_by_type](file:///c%3A/myproject/AI/auto_prompt_system.py#L454-L479)方法以支持更多类型的结果处理

## 错误处理

系统包含完善的错误处理机制：
- API调用错误
- 网络连接问题
- 配置缺失问题
- JSON解析错误
- 文件操作错误

当没有配置API密钥时，系统会自动切换到模拟模式，方便开发和测试。

# AI自动化系统

这是一个完整的AI自动化系统，包含多个模块，能够处理各种AI任务，从简单的文本生成到复杂的自主决策任务。

## 系统特点

1. **一体化设计** - 所有功能整合到一个统一入口程序中
2. **多模型支持** - 系统支持多种AI模型，可以根据任务需求自动选择合适的模型
3. **Token管理** - 实时跟踪和管理token使用情况
4. **文件格式自适应** - 根据内容类型自动选择合适的文件格式进行保存
5. **中文支持** - 完整的中文界面和内容处理
6. **自动提示词优化** - 自动生成和优化提示词以获得更好的结果
7. **自主决策** - 系统可以完全自主决策和执行任务
8. **本地文件读取** - 支持读取用户本地文件并将其内容提供给AI
9. **统一入口** - 所有功能通过一个程序访问，简洁易用

## 系统架构

系统是一个统一的全自动AI系统，包含以下核心功能：

1. **需求解析与文件读取** - 智能分析用户输入的自然语言需求，并读取引用的本地文件
2. **AI模型选择** - 让最聪明的AI模型分析需求并从可用模型中选择最适合的模型
3. **提示词生成** - 让AI自动生成高质量的提示词
4. **AI任务执行** - 将提示词传递给AI系统执行具体任务
5. **结果处理** - 根据任务类型自动处理执行结果（如保存代码文件、文档等）
6. **报告生成** - 自动生成任务完成报告，并保存为Markdown文件

## 环境配置

1. 复制 `.env.example` 文件为 `.env`
2. 在 `.env` 文件中配置您的API密钥和其他设置

### 支持的模型

系统支持阿里云百炼平台上的多种Qwen模型，包括但不限于：

#### 文本生成模型
- qwen-turbo - 超大规模语言模型
- qwen-turbo-2024-06-24 - Turbo模型快照版本
- qwen-plus - 超大规模语言模型增强版
- qwen-plus-2024-08-06 - Plus模型快照版本
- qwen-max - 旗舰级超大规模语言模型
- qwen-max-2024-04-28 - Max模型快照版本
- qwen-max-2024-09-19 - Max模型快照版本
- qwen3 - 最新版本的通义千问模型
- qwen3-235b-a22b - Qwen3旗舰模型
- qwen2.5 - 通义千问2.5版本
- qwen2.5-max - Qwen2.5 Max版本
- qwen2.5-turbo - Qwen2.5 Turbo版本
- qwen2 - 通义千问2版本
- qwen1.5 - 通义千问1.5版本
- qwen-long - 支持超长上下文的模型
- qwen-omni-turbo-2025-01-19 - Omni Turbo模型
- qwen-coder-turbo-0919 - 面向编程的Turbo模型

#### 多模态模型
- qwen-vl-max - 视觉理解旗舰模型
- qwen-vl-plus - 视觉理解增强模型
- qwen-vl-plus-2025-01-25 - VL Plus模型快照版本

#### 音频模型
- qwen-audio-turbo-1204 - 音频处理Turbo模型
- qwen-audio-turbo-0807 - 音频处理Turbo模型

#### 数学和编程推理模型
- qwen-omni - 多模态推理模型
- qwq-32b-preview - 专注于推理的模型

#### 开源模型
- qwen2-72b-instruct - Qwen2 72B指令模型
- qwen2-57b-a14b-instruct - Qwen2 57B+A14B指令模型
- qwen2-7b-instruct - Qwen2 7B指令模型
- qwen1.5-110b-chat - Qwen1.5 110B对话模型
- qwen1.5-72b-chat - Qwen1.5 72B对话模型
- qwen1.5-32b-chat - Qwen1.5 32B对话模型
- qwen1.5-14b-chat - Qwen1.5 14B对话模型
- qwen1.5-7b-chat - Qwen1.5 7B对话模型

## 本地文件读取功能

系统现在支持读取用户本地文件并将其内容提供给AI作为上下文。用户可以在请求中使用以下语法引用本地文件：

```
请分析[file:./example.txt]中的内容，并提供总结。
```

系统会自动读取指定的文件，并将其内容作为上下文提供给AI。支持的文件类型包括：

- 文本文件（.txt, .md, .py, .js, .java, .cpp, .c, .h, .html, .css, .xml, .json, .yaml, .yml）
- PDF文件（.pdf）- 内容将以简化方式处理
- 图像文件（.png, .jpg, .jpeg, .gif, .bmp, .webp）- 将被编码为base64格式并自动选择视觉理解模型

## 安装依赖

```
pip install -r requirements.txt
```

## 使用方法

### 统一入口程序（推荐）

```
python ai_unified_system.py
```

运行后，系统会显示菜单供您选择所需的功能模式：

1. **自动提示词生成系统** - 全自动执行模式
   - 让最聪明的AI模型分析需求并选择合适的模型
   - 自动生成和优化提示词
   - 执行AI任务并处理结果
   - 生成详细任务报告和提示词文件

2. **纯粹AI管道系统** - 完全由AI决策
   - 用户输入需求
   - AI完全自主分析、决策和执行
   - 程序只负责保存AI生成的结果
   - 生成详细任务报告和提示词文件

3. **终极AI系统** - AI完全自主执行
   - 用户表达意愿
   - AI完全自主理解和执行
   - 程序仅作为执行环境和保存器
   - 生成详细任务报告和提示词文件

4. **通用AI生成器** - 通用内容生成
   - 用户输入任何请求
   - 系统自动分析并处理
   - 生成相应内容并保存
   - 生成详细任务报告和提示词文件

## 文件命名规范

系统采用统一的文件命名规范：

- 提示词文件：`提示词_{关键词}_{时间戳}.md`
- 内容文件：`内容_{类型}_{关键词}_{时间戳}.{扩展名}`
- 报告文件：`报告_{关键词}_{时间戳}.md`

## 输出格式支持

系统支持多种输出格式：
- 文本文件 (.txt)
- Markdown文档 (.md)
- PDF文档 (.pdf)
- 代码文件 (根据语言确定扩展名)
- 图像文件 (.png, .jpg等)

# 真正全自动AI系统

## 项目简介

这是一个真正全自动的AI系统，用户只需输入需求，系统就能全自动完成所有工作。系统集成了模型选择、提示词优化、任务执行、结果评估和报告生成等完整流程，实现了端到端的AI自动化处理。

**注意：当前项目已经整合了早期开发阶段的所有功能模块，形成了一个统一的全自动AI系统。**

## 核心功能

### 1. 全自动任务处理流程
- **需求输入**：用户只需输入自然语言需求
- **智能文件解析**：自动识别并读取请求中引用的本地文件，提供更清晰的文件内容标识
- **智能模型选择**：AI自动分析任务并选择最适合的模型
- **提示词优化**：AI自动生成优化的提示词
- **任务执行**：调用AI模型执行具体任务
- **结果评估**：AI自动评估执行结果质量
- **智能文件保存**：根据内容类型自动选择合适的文件格式和扩展名

### 2. 智能模型管理
- 支持多种阿里云百炼平台Qwen模型
- AI自动根据任务复杂度选择最适合的模型
- 实时获取平台真实的token使用数据
- 避免模型过载，确保稳定运行

### 3. 多格式文件支持
- **代码文件**：Python、Java、JavaScript、C++、PHP等
- **文档文件**：Markdown、纯文本
- **自动格式识别**：根据内容类型自动选择合适格式
- **文件名优化**：自动生成合法且有意义的文件名

### 4. 完整报告系统
- 任务执行综合报告
- 模型选择分析
- Token使用统计（平台真实数据）
- 结果质量评估

## 系统架构

```
+-------------------+
|   用户需求输入    |
+-------------------+
          |
          v
+-------------------+
|  需求解析与文件读取 |
+-------------------+
          |
          v
+-------------------+
| AI智能模型选择模块 |
+-------------------+
          |
          v
+-------------------+
| AI提示词生成模块  |
+-------------------+
          |
          v
+-------------------+
|   AI任务执行模块   |
+-------------------+
          |
          v
+-------------------+
|  结果评估与处理模块 |
+-------------------+
          |
          v
+-------------------+
|   文件保存模块    |
+-------------------+
```

## 使用方法

### 1. 环境配置
```bash
# 1. 安装依赖
pip install -r requirements.txt

# 2. 配置API密钥
cp .env.example .env
# 编辑.env文件，填入您的阿里云API密钥
```

### 2. 运行系统
```bash
python main.py
```

### 3. 输入需求示例
```
请分析[file:report.txt]中的内容并生成总结报告
```

系统将全自动完成：
1. 读取report.txt文件
2. 分析任务类型和复杂度
3. 自动选择最适合的AI模型
4. 生成优化提示词
5. 执行任务并生成总结报告
6. 评估结果质量
7. 保存所有生成文件
8. 生成详细执行报告

## 文件引用语法

在任何请求中使用以下语法引用本地文件：
```
[file:文件路径]
```

示例：
- `[file:document.txt]`
- `[file:./data/report.pdf]`
- `[file:/home/user/input.md]`

系统会自动读取这些文件，并在请求中以清晰的标识展示文件内容：
```
[文件内容开始:文件路径]
...文件内容...
[文件内容结束:文件路径]
```

这种方式帮助AI更好地理解和利用文件内容来完成任务。

## 支持的模型

系统支持阿里云百炼平台上的多种Qwen模型：

- **qwen-turbo**：快速处理简单任务
- **qwen-plus**：平衡处理中等复杂任务
- **qwen-max**：强大处理复杂任务
- **qwen-long**：处理超长文本

AI会根据任务需求自动选择最适合的模型，用户也可以通过修改环境变量来配置默认模型。

## 生成的文件类型

系统会自动生成以下三种类型的文件：

### 1. 结果文件
AI任务执行的主要结果，根据内容类型自动选择格式：
- 代码内容：.py、.java、.js等
- 文档内容：.md、.txt等

### 2. 提示词文件
AI用于执行任务的优化提示词，保存为Markdown格式：
- 文件名格式：`AI提示词_{关键词}_{时间戳}.md`

### 3. 执行报告
包含任务详细信息的综合报告：
- 原始请求和执行时间
- 模型选择分析
- Token使用统计（平台真实数据）
- 结果质量评估
- 文件名格式：`AI执行报告_{关键词}_{时间戳}.md`

## 项目结构

```
AI/
├── main.py                 # 系统主程序（整合了所有功能）
├── model_manager.py        # 模型管理器
├── requirements.txt        # 依赖包列表
├── .env.example           # 环境变量配置示例
├── .env                   # 环境变量配置（需手动创建）
└── README.md              # 项目说明文档
```

## 历史版本说明

在项目的早期开发阶段，我们创建了多个不同的系统版本用于探索和测试不同的实现方式：

1. **自动提示词生成系统** - 全自动执行模式，分析需求并生成优化提示词
2. **纯粹AI管道系统** - 完全由AI负责决策和执行的管道系统
3. **终极AI系统** - 完全自主的AI系统，AI负责所有任务
4. **通用AI生成器** - 通用的内容生成器，处理各种类型的AI内容生成任务

**这些系统版本现已全部整合到当前的统一系统中**，即[main.py](file:///c%3A/myproject/AI/main.py)文件。这种整合避免了功能重复，简化了项目结构，提高了维护效率。

## 技术特点

### 1. 真实数据驱动
- 所有Token使用数据均为平台返回的真实计量数据
- 根据阿里云百炼平台API文档获取usage字段信息
- 总Token数量 = 输入Token数 + 输出Token数

### 2. 智能内容识别
- 自动识别代码内容并选择合适编程语言格式
- 自动识别Markdown内容并保存为.md文件
- 其他内容默认保存为.txt文件

### 3. 完善的错误处理
- 网络异常处理
- API调用错误处理
- 文件读写错误处理
- 模型选择失败处理
- JSON解析错误处理

### 4. 模块化设计
- 核心功能模块化，便于维护和扩展
- 清晰的类和方法设计
- 详细的代码注释

## 依赖说明

- `openai>=1.0.0`：阿里云百炼平台API调用
- `python-dotenv>=0.19.0`：环境变量管理
- `PyYAML>=6.0`：YAML配置文件解析
- `Jinja2>=3.1.0`：提示词模板渲染
- `requests>=2.28.0`：HTTP请求处理
- `reportlab>=3.6.0`：PDF报告生成（预留功能）

## 开发与维护

本项目采用简洁的设计理念，所有核心功能都集成在main.py中，便于理解和维护。model_manager.py负责模型管理和token统计，prompt_templates.yaml提供提示词模板支持。

## 许可证

本项目基于 Alan Global Copyright Protection Agreement (AGCPA v3.0) 开源协议进行授权。© 2024-2025 Alan. 全球保留所有权利。

详细协议内容请参阅 [AGCPA v3.0.md](https://ima.qq.com/note/share?shareId=_AseMbuM8w6eLpIXZlZgMg) 文件或访问官方链接了解详细信息：https://ima.qq.com/note/share?shareId=_AseMbuM8w6eLpIXZlZgMg